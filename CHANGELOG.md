# Initial version (January 31, 2025)

- âœ… Make sponsorflare + chatcompletions wrapped backend work (allow $1 free) - start from sponsorflare.chat
- âœ… Add logged user profile to header (header.js) that also shows setting to change LLM
- âœ… Fix local login `/callback`
- Fix chatcompletions.com error and ensure chatting works
- âœ… Add other model names and api keys (openai, anthropic)

# Tiny improvements

prompt:

- Create system prompt to output with `<content path="">some code or 'null' to delete</content>` etc similar to what i had for filetransformers, but using xml

Tabs;

- Button for copying context to clipboard
- add outlink that navigates to the URL of the selected context in headerbar (icon)
- Show token count at menu tab (reads textarea value length / 5)

Chat

- Ensure loading shows at the location where the new message will be
- Render markdown in response
- Codeblock color highlighting
- Buttons to copy codeblocks and copy responses
- Chat input must be textarea
- Allow darkmode by simply inverting all colors
- Render `<think>` and any other raw tag, not in codeblock, as expandible things

Nav

- Hide bin icon until hover, align at the right of the menu item, change to 'x'
- When clicking a menu item, focus on chat input
- Context retrieval should go via proxy to avoid error. Should return urls for screenshot/content/html for html urls.
- If added context is of type html, allow choosing screenshot/content/html and set context-item appropriately.

Misc

- Add status via status API for providers

ðŸ”¥ Add githuw (context-driven LLM chat) to forgithub and uithub.cf header

ðŸ”¥ Now fix patching and allow patching from response with `<code>`
